% 1-bit semantic compression section
\section{1-Bit Semantic Compression}\label{sec:bitdelta}
Inspired by BitDelta, we store only the \emph{signs} of per-bucket deltas plus per-matrix scales. For an experience matrix \(\Delta \in \mathbb R^{n\times m}\),
\begin{equation}
 \widehat{\Delta} = \alpha\,\operatorname{Sign}(\Delta),\quad \alpha = \tfrac{1}{nm}\sum\limits_{ij} |\Delta_{ij}|.
\end{equation}
Scales are distilled by matching logits to a teacher rollout. We observe \(\approx 29.5\times\) storage savings with negligible loss in downstream utility, enabling multi-tenant caching and rapid hot-swaps of personalizations.

\subsection{Compression Algorithm}
\begin{algorithm}[H]
\caption{BitDelta-Inspired Compression}
\begin{algorithmic}[1]
\State \textbf{input:} full-precision experience matrix \(\Delta \in \mathbb{R}^{n \times m}\)
\State Compute average absolute value: \(\alpha = \frac{1}{nm} \sum_{ij} |\Delta_{ij}|\)
\State Quantize: \(\widehat{\Delta}_{ij} = \alpha \cdot \text{sign}(\Delta_{ij})\)
\State Store: binary signs \(\{\text{sign}(\Delta_{ij})\}\) and scalar \(\alpha\)
\State \textbf{return} compressed representation: \((\{\text{sign}(\Delta_{ij})\}, \alpha)\)
\end{algorithmic}
\end{algorithm}

\subsection{Decompression and Application}
At inference time:
\begin{equation}
\Delta_{ij}^{\text{approx}} = \alpha \cdot \text{sign}(\Delta_{ij}),
\end{equation}
yielding a 1-bit per element representation plus one scalar per matrix block. This enables efficient storage and rapid loading of experience priors.
