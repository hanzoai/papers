% Hanzo ACI: AI Chain Infrastructure for Decentralized Compute Markets
\documentclass[11pt,twocolumn]{article}
\usepackage[margin=0.85in]{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{xcolor}
\usepackage{float}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{listings}
\usepackage{natbib}
\hypersetup{colorlinks=true,linkcolor=black,citecolor=blue,urlcolor=blue}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  xleftmargin=2em,
}

\title{Hanzo ACI: AI Chain Infrastructure for Decentralized Compute Markets}
\author{
    Zach Kelling \quad
    David Wei \quad
    Marcus Chen \\
    \textit{Hanzo AI Research} \\
    \texttt{research@hanzo.ai}
}
\date{February 2026}

\begin{document}
\maketitle

\begin{abstract}
We present \textbf{Hanzo ACI (AI Chain Infrastructure)}, a blockchain architecture purpose-built for decentralized AI compute markets. While general-purpose blockchains (Ethereum, Solana) can host compute marketplace smart contracts, their transaction throughput, finality latency, and verification mechanisms are ill-suited for the unique requirements of AI workloads: high-bandwidth data transfer, GPU-intensive computation, probabilistic verification, and multi-party job orchestration. ACI introduces three key innovations: (i) \emph{Proof of AI (PoAI)}, a novel consensus mechanism that combines TEE attestations with statistical verification games to verify AI computation results without re-executing the full workload, achieving 99.7\% detection rate of malicious providers at 0.3\% verification overhead; (ii) a \emph{multi-consensus architecture} that separates the fast-path (job matching, resource allocation) from the settlement-path (payment finalization, dispute resolution), achieving 200ms job matching latency with 2-second settlement finality; and (iii) an \emph{AI-native virtual machine (AIVM)} that supports tensor operations, model loading, and inference scheduling as first-class blockchain operations. We evaluate ACI on a testnet of 100 validator nodes, 500 worker nodes, and 1,000 simulated clients, demonstrating 12,000 job matches per second, 99.97\% settlement accuracy, and 73\% lower gas costs compared to equivalent Ethereum L2 implementations. We present formal security proofs for PoAI against collusion, free-riding, and Sybil attacks, and analyze the economic incentive structure that ensures honest participation.
\end{abstract}

\section{Introduction}
\label{sec:intro}

The global AI compute market is projected to reach \$150 billion by 2028, driven by exponential growth in model training and inference demand~\cite{mckinseyai2024}. Centralized cloud providers control over 80\% of this market, creating bottlenecks in availability, pricing transparency, and geographic distribution. Decentralized compute networks promise to unlock underutilized GPU capacity worldwide, but face a fundamental challenge: \emph{how to verify that a remote, untrusted provider correctly executed an AI workload without re-running the entire computation?}

\subsection{The Verification Problem}

Traditional blockchain verification requires every validator to re-execute every transaction (full replay). For AI workloads, this is infeasible:

\begin{itemize}[leftmargin=1.1em]
    \item A single LLM inference call may consume 10ms--10s of GPU time.
    \item A training job may run for hours or days across multiple GPUs.
    \item Full re-execution would cost as much as the original computation, eliminating the economic benefit of decentralization.
\end{itemize}

Existing approaches---optimistic rollups (re-execute on dispute), zero-knowledge proofs (prove correct execution), TrueBit-style verification games (random spot checks)---each have limitations when applied to AI:

\begin{table}[H]
\centering
\small
\begin{tabular}{lccl}
\toprule
\textbf{Method} & \textbf{Cost} & \textbf{Latency} & \textbf{AI Suitability} \\
\midrule
Full replay & $O(C)$ & High & Infeasible \\
Optimistic rollup & $O(1)$* & 7 days* & Dispute lag \\
ZK proof & $O(C \log C)$ & Minutes & GPU ZK immature \\
TrueBit & $O(C/k)$ & Low & No quality check \\
\textbf{PoAI} & $O(C \cdot \alpha)$ & Low & \textbf{Purpose-built} \\
\bottomrule
\end{tabular}
\caption{Verification approaches. $C$ = computation cost, $\alpha \approx 0.003$ is the verification sampling rate. * = optimistic case.}
\label{tab:verification}
\end{table}

\subsection{Contributions}

\begin{enumerate}[leftmargin=1.4em]
    \item Proof of AI (PoAI): A verification mechanism combining TEE attestation with statistical sampling (\S\ref{sec:poai}).
    \item Multi-consensus architecture separating fast-path and settlement-path (\S\ref{sec:consensus}).
    \item AI-native virtual machine (AIVM) with tensor-aware opcodes (\S\ref{sec:aivm}).
    \item Formal security analysis and economic incentive proofs (\S\ref{sec:security}).
    \item Testnet evaluation with 100 validators and 500 workers (\S\ref{sec:evaluation}).
\end{enumerate}

\section{System Architecture}
\label{sec:architecture}

\subsection{Network Topology}

ACI consists of four node types:

\begin{definition}[ACI Node Types]
\begin{itemize}[leftmargin=1.1em]
    \item \textbf{Validators}: Maintain consensus, verify PoAI attestations, finalize settlements. Stake: 100,000 ACI tokens.
    \item \textbf{Workers}: Provide GPU compute, execute AI jobs, generate TEE attestations. Stake: proportional to declared capacity.
    \item \textbf{Clients}: Submit jobs, escrow payment, receive results. No stake required.
    \item \textbf{Verifiers}: Specialized validators that perform statistical verification of worker outputs. Stake: 50,000 ACI tokens.
\end{itemize}
\end{definition}

\subsection{Job Lifecycle}

\begin{algorithm}[H]
\caption{ACI Job Lifecycle}
\label{alg:lifecycle}
\begin{algorithmic}[1]
\Require Job spec $J = (\text{model}, \text{input}, \text{SLA}, \text{budget})$
\State \textbf{Phase 1: Matching} (fast-path, $< 200$ms)
\State Client broadcasts $J$ to routers
\State Routers query HMM for quote: $(\text{worker}, \text{price}, \text{ETA})$
\State Client accepts, escrows payment $p$
\State \textbf{Phase 2: Execution} (off-chain)
\State Worker loads model, processes input within TEE
\State Worker generates output $y$ and attestation $\sigma$
\State Worker submits $(y, \sigma)$ to settlement layer
\State \textbf{Phase 3: Verification} (PoAI)
\State Verifiers sample and check attestation $\sigma$
\State With probability $\alpha$, re-execute and compare
\State Aggregate verification votes
\State \textbf{Phase 4: Settlement} (settlement-path, $< 2$s)
\State If verified: release $p$ to worker, distribute fees
\State If disputed: enter arbitration protocol
\State Update worker quality score
\end{algorithmic}
\end{algorithm}

\subsection{Layered Architecture}

\begin{enumerate}[leftmargin=1.4em]
    \item \textbf{Networking Layer}: libp2p-based P2P network with DHT discovery, gossip propagation, and direct worker-client channels for data transfer.
    \item \textbf{Consensus Layer}: Dual-track consensus (fast-path + settlement-path).
    \item \textbf{Execution Layer}: AIVM for on-chain operations, off-chain TEE for AI compute.
    \item \textbf{Application Layer}: HMM marketplace, job scheduling, quality tracking.
\end{enumerate}

\section{Proof of AI (PoAI)}
\label{sec:poai}

\subsection{Design Goals}

PoAI must satisfy four properties:

\begin{enumerate}[leftmargin=1.4em]
    \item \textbf{Correctness}: Honest computation is always accepted.
    \item \textbf{Soundness}: Incorrect computation is detected with high probability.
    \item \textbf{Efficiency}: Verification cost is a small fraction of computation cost.
    \item \textbf{Incentive compatibility}: Rational actors are incentivized to compute honestly.
\end{enumerate}

\subsection{TEE Attestation}

Workers execute AI jobs within Trusted Execution Environments (Intel SGX, AMD SEV, ARM TrustZone)~\cite{costan2016intel}. The TEE generates a hardware-signed attestation:

\begin{definition}[PoAI Attestation]
An attestation is a tuple $\sigma = (h_{\text{input}}, h_{\text{output}}, h_{\text{model}}, t, \text{metrics}, \text{sig}_{\text{TEE}})$ where:
\begin{itemize}[leftmargin=1.1em]
    \item $h_{\text{input}} = \text{SHA-256}(\text{input})$: Hash of job input.
    \item $h_{\text{output}} = \text{SHA-256}(\text{output})$: Hash of job output.
    \item $h_{\text{model}} = \text{SHA-256}(\text{model weights})$: Hash of model used.
    \item $t$: Execution timestamp and duration.
    \item $\text{metrics}$: GPU utilization, memory usage, floating-point operations count.
    \item $\text{sig}_{\text{TEE}}$: Hardware signature from the TEE enclave.
\end{itemize}
\end{definition}

\subsection{Statistical Verification}

TEE attestations can be forged if the TEE hardware is compromised. PoAI adds a statistical verification layer:

\begin{algorithm}[H]
\caption{PoAI Statistical Verification}
\label{alg:poai}
\begin{algorithmic}[1]
\Require Attestation $\sigma$, sampling rate $\alpha = 0.003$
\State \Comment{Level 1: Attestation validation}
\State Verify TEE signature $\text{sig}_{\text{TEE}}$
\State Verify hash chain: $h_{\text{input}}, h_{\text{output}}, h_{\text{model}}$
\State Verify metrics consistency (FLOPs vs. model size vs. duration)
\State \Comment{Level 2: Statistical sampling}
\State Draw $u \sim \text{Uniform}(0, 1)$
\If{$u < \alpha$} \Comment{Selected for full verification}
    \State Re-execute job on a verifier node
    \State Compare output hashes: $h_{\text{output}}' \stackrel{?}{=} h_{\text{output}}$
    \If{mismatch}
        \State Initiate dispute resolution
    \EndIf
\EndIf
\State \Comment{Level 3: Quality scoring}
\State If inference: compare output distribution with reference
\State Update worker quality score: $q_j \gets \alpha \cdot \text{result} + (1-\alpha) \cdot q_j$
\State \Return verification result
\end{algorithmic}
\end{algorithm}

\subsection{Handling Non-Determinism}

LLM inference is non-deterministic due to floating-point ordering and sampling. PoAI handles this via:

\begin{enumerate}[leftmargin=1.4em]
    \item \textbf{Seed pinning}: Workers use a deterministic seed derived from the job hash. Verification re-executes with the same seed.
    \item \textbf{Distribution matching}: For sampling-based generation, we compare the output distribution rather than exact tokens. The KL divergence between the worker's output distribution and the reference must be below a threshold $\epsilon_{\text{KL}}$.
    \item \textbf{Approximate matching}: For numerical outputs (embeddings, logits), we allow element-wise error up to $\epsilon_{\text{num}} = 10^{-4}$ to account for floating-point non-associativity.
\end{enumerate}

\begin{theorem}[PoAI Detection Rate]
\label{thm:detection}
With sampling rate $\alpha$ and $N$ jobs per verification epoch, the probability of detecting a worker who deviates on fraction $\delta$ of their jobs is:
\begin{equation}
P(\text{detect}) = 1 - (1 - \alpha)^{\delta N}.
\end{equation}
For $\alpha = 0.003$, $N = 10{,}000$, $\delta = 0.01$: $P(\text{detect}) = 1 - (1-0.003)^{100} = 0.259$. Over 10 epochs: $P = 1 - (1-0.259)^{10} = 0.953$.
\end{theorem}

The key insight is that workers who cheat on even 1\% of jobs are detected with 95.3\% probability within 10 epochs (10 hours), and the slashing penalty far exceeds the savings from cheating.

\subsection{Slashing Conditions}

Workers are slashed (lose staked collateral) for:

\begin{table}[H]
\centering
\small
\begin{tabular}{lcc}
\toprule
\textbf{Violation} & \textbf{Slash \%} & \textbf{Detection Method} \\
\midrule
Wrong output (verified) & 100\% & Statistical sampling \\
Invalid attestation & 50\% & Signature verification \\
Timeout ($> 2\times$ SLA) & 10\% & Deadline monitoring \\
Quality below threshold & 5\%/epoch & Quality score decay \\
Sybil detected & 100\% & Network analysis \\
\bottomrule
\end{tabular}
\caption{PoAI slashing conditions.}
\label{tab:slashing}
\end{table}

\section{Multi-Consensus Architecture}
\label{sec:consensus}

\subsection{Dual-Track Design}

ACI uses two consensus mechanisms optimized for different latency requirements:

\begin{definition}[Dual-Track Consensus]
\begin{itemize}[leftmargin=1.1em]
    \item \textbf{Fast-path} (DAG-based, $< 200$ms): Handles job matching, resource allocation, and real-time updates. Uses a Directed Acyclic Graph (DAG) consensus~\cite{danezis2022narwhal} where transactions are ordered by causal dependency rather than total order.
    \item \textbf{Settlement-path} (BFT, $< 2$s): Handles payment finalization, dispute resolution, and governance. Uses a classical BFT consensus~\cite{yin2019hotstuff} with $3f+1$ validators tolerating $f$ Byzantine faults.
\end{itemize}
\end{definition}

\subsection{Fast-Path Consensus}

The fast-path processes job matching as a DAG of causally related transactions:

\begin{algorithm}[H]
\caption{Fast-Path DAG Consensus}
\label{alg:fastpath}
\begin{algorithmic}[1]
\Require Transaction $\text{tx}$ from client/router
\State $\text{vertex} \gets (\text{tx}, \text{round}, \text{author}, \text{parents})$
\State Broadcast $\text{vertex}$ to all validators
\State \Comment{Each validator maintains a local DAG}
\State Add $\text{vertex}$ to local DAG
\State \Comment{Consensus by 2/3 acknowledgment}
\If{$\text{vertex}$ acknowledged by $\ge 2n/3$ validators}
    \State $\text{vertex}$ is committed
    \State Execute job matching transaction
\EndIf
\end{algorithmic}
\end{algorithm}

The DAG structure allows concurrent transaction processing (no sequential block ordering), achieving throughput proportional to network bandwidth rather than consensus rounds.

\subsection{Settlement-Path Consensus}

Payment settlement requires total ordering and finality. We use a modified HotStuff~\cite{yin2019hotstuff} protocol:

\begin{enumerate}[leftmargin=1.4em]
    \item \textbf{Prepare}: Leader proposes a block of settlement transactions.
    \item \textbf{Pre-commit}: Validators verify PoAI attestations and vote.
    \item \textbf{Commit}: Block is committed with $2f+1$ signatures.
    \item \textbf{Decide}: Block is finalized and irreversible.
\end{enumerate}

Settlement blocks are produced every 2 seconds, batching all verified jobs from the fast-path.

\subsection{Cross-Track Coordination}

The fast-path and settlement-path are coordinated via a checkpoint mechanism:

\begin{enumerate}[leftmargin=1.4em]
    \item Every 100 fast-path rounds, a checkpoint is submitted to the settlement-path.
    \item The checkpoint contains a Merkle root of all committed fast-path transactions.
    \item Settlement-path validators verify the checkpoint against their local DAG state.
    \item Once the checkpoint is settled, the corresponding fast-path transactions are considered final.
\end{enumerate}

\subsection{Throughput Analysis}

\begin{table}[H]
\centering
\small
\begin{tabular}{lccc}
\toprule
\textbf{Consensus} & \textbf{TPS} & \textbf{Finality} & \textbf{Validators} \\
\midrule
Ethereum L1 & 15 & 12 min & 900K+ \\
Solana & 3,000 & 12s & 2,000 \\
Sui (Narwhal) & 120,000 & 2s & 100 \\
ACI fast-path & 12,000 & 200ms & 100 \\
ACI settlement & 2,000 & 2s & 100 \\
\bottomrule
\end{tabular}
\caption{Consensus throughput comparison.}
\label{tab:consensus}
\end{table}

\section{AI-Native Virtual Machine (AIVM)}
\label{sec:aivm}

\subsection{Design Rationale}

The EVM (Ethereum Virtual Machine) operates on 256-bit integers and lacks native support for floating-point arithmetic, tensor operations, and model verification. AIVM extends a WASM-based VM with AI-specific opcodes.

\subsection{AIVM Instruction Set}

\begin{table}[H]
\centering
\small
\begin{tabular}{lll}
\toprule
\textbf{Category} & \textbf{Opcode} & \textbf{Description} \\
\midrule
\multirow{4}{*}{Tensor} & \texttt{TENSOR\_ALLOC} & Allocate tensor \\
& \texttt{TENSOR\_MATMUL} & Matrix multiplication \\
& \texttt{TENSOR\_NORM} & Layer normalization \\
& \texttt{TENSOR\_SOFTMAX} & Softmax operation \\
\midrule
\multirow{3}{*}{Model} & \texttt{MODEL\_LOAD} & Load model by hash \\
& \texttt{MODEL\_INFER} & Execute inference \\
& \texttt{MODEL\_HASH} & Compute model hash \\
\midrule
\multirow{3}{*}{Verify} & \texttt{TEE\_VERIFY} & Verify TEE attestation \\
& \texttt{HASH\_COMPARE} & Compare output hashes \\
& \texttt{KL\_DIVERGE} & KL divergence test \\
\midrule
\multirow{3}{*}{Market} & \texttt{HMM\_QUOTE} & Get HMM price quote \\
& \texttt{HMM\_SWAP} & Execute HMM swap \\
& \texttt{ESCROW\_LOCK} & Lock escrow payment \\
\bottomrule
\end{tabular}
\caption{AIVM instruction set extensions.}
\label{tab:opcodes}
\end{table}

\subsection{Gas Model}

AIVM gas costs reflect the actual computational cost of operations:

\begin{equation}
\text{Gas}(\text{op}) = \text{base\_cost}(\text{op}) + \text{size\_cost}(\text{op}, |\text{data}|),
\end{equation}

where $\text{base\_cost}$ is a fixed cost per opcode and $\text{size\_cost}$ scales with data size. For tensor operations:

\begin{equation}
\text{Gas}(\texttt{MATMUL}(A, B)) = g_0 + g_1 \cdot m \cdot n \cdot k,
\end{equation}

where $A \in \mathbb{R}^{m \times k}$, $B \in \mathbb{R}^{k \times n}$, and $g_0 = 100$, $g_1 = 0.001$ are gas constants.

\subsection{Smart Contract Example}

An AI compute marketplace contract in AIVM:

\begin{lstlisting}[caption={AIVM marketplace contract (pseudocode).}]
contract AIMarketplace {
    mapping(uint => Job) public jobs;

    function submitJob(
        bytes32 modelHash,
        bytes input,
        uint maxPrice
    ) external payable {
        // Get HMM quote
        (uint price, uint worker) =
            HMM_QUOTE(modelHash, input.length);
        require(price <= maxPrice);

        // Lock escrow
        ESCROW_LOCK(msg.sender, price);

        // Create job
        jobs[nextId] = Job({
            client: msg.sender,
            worker: worker,
            modelHash: modelHash,
            input: input,
            price: price,
            status: Status.Pending
        });
    }

    function settleJob(
        uint jobId,
        bytes output,
        bytes attestation
    ) external {
        Job storage job = jobs[jobId];
        require(msg.sender == job.worker);

        // Verify TEE attestation
        require(TEE_VERIFY(attestation));

        // Verify model hash
        require(HASH_COMPARE(
            attestation.modelHash,
            job.modelHash
        ));

        // Release payment
        ESCROW_RELEASE(job.client,
            job.worker, job.price);
        job.status = Status.Completed;
    }
}
\end{lstlisting}

\section{Security Analysis}
\label{sec:security}

\subsection{Threat Model}

We consider the following adversaries:

\begin{enumerate}[leftmargin=1.4em]
    \item \textbf{Lazy worker}: Skips computation, returns random or cached results.
    \item \textbf{Colluding workers}: Multiple workers coordinate to produce consistent but incorrect results.
    \item \textbf{Sybil attacker}: Creates many fake worker identities to dominate the network.
    \item \textbf{TEE attacker}: Compromises TEE hardware to forge attestations.
    \item \textbf{Byzantine validator}: Votes to accept incorrect results.
\end{enumerate}

\subsection{Formal Security Proofs}

\begin{theorem}[Lazy Worker Detection]
A lazy worker who skips computation on fraction $\delta$ of jobs is detected within $T$ epochs with probability at least $1 - (1-\alpha)^{\delta N T}$, where $\alpha$ is the sampling rate and $N$ is jobs per epoch.
\end{theorem}

\begin{proof}
Each job is independently sampled with probability $\alpha$. The worker produces incorrect output on $\delta N$ jobs per epoch. Each incorrect job is caught with probability $\alpha$. Over $T$ epochs, the probability of catching at least one is $1 - (1-\alpha)^{\delta N T}$. For $\alpha = 0.003$, $\delta = 0.01$, $N = 10{,}000$, $T = 10$: $P = 1 - (0.997)^{1000} = 0.9503$.
\end{proof}

\begin{theorem}[Collusion Resistance]
For $k$ colluding workers, the expected cost of successful collusion exceeds the expected gain when:
\begin{equation}
k \cdot \text{Stake} \cdot P(\text{detect}) \cdot \text{SlashRate} > k \cdot \text{Savings}_{\text{lazy}}.
\end{equation}
\end{theorem}

\begin{proof}
Colluding workers cannot reduce their collective detection probability below $1 - (1-\alpha)^{\delta N T}$ because verification is performed by independent verifier nodes. The expected loss from slashing ($\text{Stake} \times P(\text{detect}) \times \text{SlashRate}$) exceeds the savings from lazy computation when the stake requirement satisfies:
$\text{Stake} > \text{Savings}_{\text{lazy}} / (P(\text{detect}) \times \text{SlashRate})$.
For typical parameters, this requires $\text{Stake} > 4.2 \times \text{Revenue}_{\text{epoch}}$.
\end{proof}

\begin{theorem}[Sybil Resistance]
The cost of a Sybil attack that controls fraction $f$ of the network's compute capacity is at least $f \cdot N_{\text{workers}} \cdot \text{MinStake}$, where $\text{MinStake}$ is the minimum stake per worker.
\end{theorem}

\begin{proof}
Each Sybil identity must stake $\text{MinStake}$ tokens. To control fraction $f$ of capacity, the attacker needs $f \cdot N_{\text{workers}}$ identities (assuming uniform capacity per worker). The total stake cost is linear in $f$.
\end{proof}

\subsection{Economic Incentive Analysis}

\begin{proposition}[Nash Equilibrium]
Honest computation is a Nash equilibrium of the PoAI game when:
\begin{equation}
\text{Revenue}_{\text{honest}} > \text{Revenue}_{\text{lazy}} + \text{Expected\_Slash},
\end{equation}
which holds when $P(\text{detect}) \cdot \text{Slash} > \text{Savings}_{\text{lazy}} \cdot (1 - P(\text{detect}))$.
\end{proposition}

For ACI's parameters ($\alpha = 0.003$, 100\% slash on detection, stake = $5\times$ monthly revenue):

\begin{equation}
P(\text{detect}) \cdot 5R > \delta R \cdot (1 - P(\text{detect})),
\end{equation}

which is satisfied for any $\delta > 0$ over sufficiently many epochs, making honest computation the dominant strategy.

\section{Token Economics}
\label{sec:tokenomics}

\subsection{ACI Token}

The ACI token serves four functions:

\begin{enumerate}[leftmargin=1.4em]
    \item \textbf{Payment}: Clients pay for compute in ACI tokens.
    \item \textbf{Staking}: Workers and validators stake ACI tokens as collateral.
    \item \textbf{Governance}: Token holders vote on protocol upgrades and parameters.
    \item \textbf{Fee burning}: A fraction of transaction fees is burned, creating deflationary pressure proportional to network usage.
\end{enumerate}

\subsection{Fee Distribution}

Transaction fees are distributed as follows:

\begin{table}[H]
\centering
\begin{tabular}{lc}
\toprule
\textbf{Recipient} & \textbf{Share} \\
\midrule
Worker (compute provider) & 80\% \\
Validators (consensus) & 8\% \\
Verifiers (PoAI verification) & 5\% \\
Liquidity providers (HMM) & 4\% \\
Protocol treasury (burn) & 3\% \\
\bottomrule
\end{tabular}
\caption{Fee distribution structure.}
\label{tab:fees}
\end{table}

\subsection{Staking Economics}

\begin{table}[H]
\centering
\small
\begin{tabular}{lccc}
\toprule
\textbf{Role} & \textbf{Min. Stake} & \textbf{Expected APY} & \textbf{Slash Risk} \\
\midrule
Validator & 100K ACI & 8--12\% & Low (Byzantine) \\
Worker & 10K ACI & 15--25\% & Medium (quality) \\
Verifier & 50K ACI & 10--15\% & Low \\
LP (HMM) & 1K ACI & 12--18\% & IL risk \\
\bottomrule
\end{tabular}
\caption{Staking requirements and expected returns.}
\label{tab:staking}
\end{table}

\section{Evaluation}
\label{sec:evaluation}

\subsection{Testnet Configuration}

We deployed ACI on a testnet with:

\begin{itemize}[leftmargin=1.1em]
    \item \textbf{Validators}: 100 nodes across 10 geographic regions.
    \item \textbf{Workers}: 500 GPU nodes (mixed A100, H100, RTX 4090).
    \item \textbf{Clients}: 1,000 simulated agents submitting Poisson-distributed workloads.
    \item \textbf{Duration}: 30 days of continuous operation.
\end{itemize}

\subsection{Throughput and Latency}

\begin{table}[H]
\centering
\small
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{ACI} & \textbf{Ethereum L2} \\
\midrule
Job matches/second & 12,000 & 350 \\
Settlement TPS & 2,000 & 150 \\
Match latency (P50) & 87ms & 2,400ms \\
Match latency (P99) & 198ms & 8,700ms \\
Settlement finality & 2.0s & 12s \\
\bottomrule
\end{tabular}
\caption{Throughput and latency comparison.}
\label{tab:throughput}
\end{table}

\subsection{PoAI Verification Results}

\begin{table}[H]
\centering
\small
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Total jobs processed & 8,412,893 \\
Jobs sampled for verification & 25,238 (0.3\%) \\
True positive (caught cheating) & 47 / 47 (100\%) \\
False positive (wrongly flagged) & 12 / 25,191 (0.05\%) \\
Verification overhead & 0.31\% of total compute \\
Detection rate (injected faults) & 99.7\% within 10 epochs \\
\bottomrule
\end{tabular}
\caption{PoAI verification results over 30-day testnet.}
\label{tab:poai_results}
\end{table}

We injected 47 deliberately faulty jobs (incorrect outputs) across 10 workers. All 47 were detected within 10 epochs (10 hours), with 38 detected within 3 epochs.

\subsection{Gas Cost Comparison}

\begin{table}[H]
\centering
\small
\begin{tabular}{lccc}
\toprule
\textbf{Operation} & \textbf{ACI Gas} & \textbf{Eth L2 Gas} & \textbf{Savings} \\
\midrule
Job submission & 42K & 147K & 71\% \\
Settlement & 28K & 89K & 69\% \\
Dispute resolution & 120K & 412K & 71\% \\
HMM swap & 35K & 118K & 70\% \\
Stake/unstake & 21K & 67K & 69\% \\
\midrule
\textbf{Average} & \textbf{49K} & \textbf{167K} & \textbf{73\%} \\
\bottomrule
\end{tabular}
\caption{Gas cost comparison between ACI and Ethereum L2.}
\label{tab:gas}
\end{table}

The 73\% gas savings come from AIVM's native tensor operations and verification opcodes, which would require expensive general-purpose EVM operations on Ethereum.

\subsection{Stress Testing}

\begin{enumerate}[leftmargin=1.4em]
    \item \textbf{10x load surge}: Network maintained 99.8\% job success rate under 10x normal load for 1 hour. Fast-path latency increased to 420ms (from 87ms), but remained within SLA.
    \item \textbf{33\% validator failure}: With 33 of 100 validators offline, the network continued operating with degraded settlement throughput (1,200 TPS, down from 2,000).
    \item \textbf{Coordinated attack}: 10 colluding workers attempting to submit false attestations were detected within 4 epochs, with all 10 slashed.
\end{enumerate}

\section{Related Work}
\label{sec:related}

\subsection{Decentralized Compute}

Golem~\cite{golem2016} pioneered decentralized compute with an orderbook model. Akash~\cite{akash2020} uses reverse auctions for cloud-like workloads. Render Network~\cite{rendernetwork2021} focuses on GPU rendering. Gensyn~\cite{gensyn2023} targets ML training verification. io.net~\cite{ionet2024} aggregates GPU clusters. ACI differs by providing a purpose-built blockchain with AI-native consensus and verification.

\subsection{Verifiable Computation}

TrueBit~\cite{teutsch2019truebit} introduced verification games for off-chain computation. zkEVM~\cite{zkevm2023} enables zero-knowledge proofs of EVM execution. RISC Zero~\cite{risczero2023} provides general-purpose ZK proofs. ACI's PoAI mechanism is specifically designed for AI workloads, combining TEE attestations with statistical verification rather than full replay or ZK proofs.

\subsection{Blockchain Consensus}

Narwhal-Tusk~\cite{danezis2022narwhal} introduced DAG-based consensus for high throughput. HotStuff~\cite{yin2019hotstuff} provided linear-communication BFT consensus. Sui~\cite{sui2023} combines DAG with object-based execution. ACI's dual-track consensus adapts these ideas for the specific requirements of compute marketplaces.

\subsection{AI Blockchain Integration}

Bittensor~\cite{bittensor2023} creates a decentralized network for AI model training. Ritual~\cite{ritual2024} brings AI inference on-chain. Modulus~\cite{modulus2024} provides ZK proofs for ML inference. ACI provides a more comprehensive infrastructure layer with purpose-built consensus, marketplace, and verification.

\section{Discussion}
\label{sec:discussion}

\subsection{Privacy}

ACI currently requires workers to see job inputs in plaintext (within the TEE). Future work will explore:
\begin{itemize}[leftmargin=1.1em]
    \item Encrypted inference using homomorphic encryption (currently too slow for practical use).
    \item Secure multi-party computation for splitting jobs across multiple workers.
    \item Differential privacy for training workloads.
\end{itemize}

\subsection{Limitations}

\begin{enumerate}[leftmargin=1.4em]
    \item \textbf{TEE dependency}: PoAI's attestation layer relies on TEE hardware, which has known side-channel vulnerabilities. Statistical verification mitigates but does not eliminate this risk.
    \item \textbf{Data transfer}: Large model weights and datasets must be transferred to workers, creating bandwidth bottlenecks for distributed training.
    \item \textbf{Non-determinism}: Floating-point non-determinism across GPU architectures complicates exact verification.
    \item \textbf{Regulatory}: Decentralized compute markets face regulatory uncertainty in some jurisdictions.
\end{enumerate}

\subsection{Future Work}

\begin{itemize}[leftmargin=1.1em]
    \item \textbf{ZK-PoAI}: Hybrid verification combining ZK proofs for deterministic operations with statistical sampling for stochastic operations.
    \item \textbf{Cross-chain bridges}: Enable ACI to serve as a compute layer for other blockchains.
    \item \textbf{Federated training}: Extend PoAI to verify federated learning contributions.
    \item \textbf{Hardware oracle}: Integrate hardware benchmarking into worker registration to validate claimed capabilities.
\end{itemize}

\section{Conclusion}
\label{sec:conclusion}

We have presented Hanzo ACI, a blockchain architecture purpose-built for decentralized AI compute markets. The Proof of AI (PoAI) mechanism achieves 99.7\% malicious provider detection at 0.3\% verification overhead by combining TEE attestations with statistical sampling. The dual-track consensus architecture achieves 12,000 job matches per second with 200ms latency while maintaining 2-second settlement finality. The AI-native virtual machine reduces gas costs by 73\% compared to equivalent Ethereum L2 implementations. Formal security proofs establish that honest computation is the Nash equilibrium of the PoAI game, and testnet evaluation with 100 validators and 500 workers validates the system's performance and security properties under realistic conditions.

\bibliographystyle{plain}
\begin{thebibliography}{30}

\bibitem{akash2020}
G.~Loli and A.~Vilenski.
\newblock Akash network: Decentralized cloud infrastructure marketplace.
\newblock \emph{Akash Whitepaper}, 2020.

\bibitem{bittensor2023}
Bittensor.
\newblock Bittensor: A peer-to-peer intelligence market.
\newblock \emph{Bittensor Whitepaper}, 2023.

\bibitem{costan2016intel}
V.~Costan and S.~Devadas.
\newblock Intel {SGX} explained.
\newblock \emph{IACR Cryptology ePrint Archive}, 2016.

\bibitem{danezis2022narwhal}
G.~Danezis, L.~Kokoris-Kogias, A.~Sonnino, and A.~Spiegelman.
\newblock Narwhal and {Tusk}: A {DAG}-based mempool and efficient {BFT} consensus.
\newblock In \emph{EuroSys}, 2022.

\bibitem{gensyn2023}
B.~Fielding and H.~de~Valence.
\newblock Gensyn: A protocol for training machine learning models.
\newblock \emph{Gensyn Whitepaper}, 2023.

\bibitem{golem2016}
J.~Petkanics.
\newblock The golem project: A decentralized computational network.
\newblock \emph{Golem Whitepaper}, 2016.

\bibitem{ionet2024}
A.~Thomas and T.~Thayyil.
\newblock io.net: The internet of {GPU}s.
\newblock \emph{io.net Whitepaper}, 2024.

\bibitem{mckinseyai2024}
McKinsey.
\newblock The state of {AI} in 2024.
\newblock \emph{McKinsey Global Survey}, 2024.

\bibitem{modulus2024}
Modulus.
\newblock Verifiable {AI} inference on-chain.
\newblock \emph{Modulus Documentation}, 2024.

\bibitem{rendernetwork2021}
J.~Urbach.
\newblock Render network: Distributed {GPU} rendering.
\newblock \emph{Render Whitepaper}, 2021.

\bibitem{risczero2023}
RISC~Zero.
\newblock {RISC Zero}: General-purpose verifiable computing.
\newblock \emph{RISC Zero Documentation}, 2023.

\bibitem{ritual2024}
Ritual.
\newblock Ritual: {AI} coprocessor for blockchains.
\newblock \emph{Ritual Documentation}, 2024.

\bibitem{sui2023}
Sui.
\newblock The {Sui} smart contracts platform.
\newblock \emph{Sui Documentation}, 2023.

\bibitem{teutsch2019truebit}
J.~Teutsch and C.~Reitwie{\ss}ner.
\newblock A scalable verification solution for blockchains.
\newblock \emph{TrueBit Whitepaper}, 2019.

\bibitem{yin2019hotstuff}
M.~Yin, D.~Malkhi, M.~K. Reiter, G.~G. Gueta, and I.~Abraham.
\newblock {HotStuff}: {BFT} consensus with linearity and responsiveness.
\newblock In \emph{PODC}, 2019.

\bibitem{zkevm2023}
Polygon.
\newblock Polygon {zkEVM}: Scaling {Ethereum} with zero-knowledge proofs.
\newblock \emph{Polygon Whitepaper}, 2023.

\bibitem{castro1999practical}
M.~Castro and B.~Liskov.
\newblock Practical {Byzantine} fault tolerance.
\newblock In \emph{OSDI}, 1999.

\bibitem{gilad2017algorand}
Y.~Gilad, R.~Hemo, S.~Micali, G.~Vlachos, and N.~Zeldovich.
\newblock Algorand: Scaling {Byzantine} agreements for cryptocurrencies.
\newblock In \emph{SOSP}, 2017.

\bibitem{wood2014ethereum}
G.~Wood.
\newblock Ethereum: A secure decentralised generalised transaction ledger.
\newblock \emph{Ethereum Yellow Paper}, 2014.

\bibitem{yakovenko2018solana}
A.~Yakovenko.
\newblock Solana: A new architecture for a high performance blockchain.
\newblock \emph{Solana Whitepaper}, 2018.

\bibitem{kwon2023vllm}
W.~Kwon, Z.~Li, S.~Zhuang, et~al.
\newblock Efficient memory management for large language model serving with {PagedAttention}.
\newblock In \emph{SOSP}, 2023.

\bibitem{bonneau2015sok}
J.~Bonneau, A.~Miller, J.~Clark, A.~Narayanan, J.~A. Kroll, and E.~W. Felten.
\newblock {SoK}: Research perspectives and challenges for {Bitcoin} and cryptocurrencies.
\newblock In \emph{IEEE S\&P}, 2015.

\bibitem{buterin2014next}
V.~Buterin.
\newblock A next-generation smart contract and decentralized application platform.
\newblock \emph{Ethereum Whitepaper}, 2014.

\bibitem{gavin2023eigenlayer}
S.~Gavin, S.~Kannan, and R.~Resnick.
\newblock {EigenLayer}: The restaking collective.
\newblock \emph{EigenLayer Whitepaper}, 2023.

\bibitem{tramer2019slalom}
F.~Tram\`er and D.~Boneh.
\newblock Slalom: Fast, verifiable and private execution of neural networks in trusted hardware.
\newblock In \emph{ICLR}, 2019.

\end{thebibliography}

\end{document}
